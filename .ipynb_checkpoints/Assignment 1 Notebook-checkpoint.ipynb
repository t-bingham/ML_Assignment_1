{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'assignment1-2019-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9000 entries, 0 to 8999\n",
      "Data columns (total 5 columns):\n",
      "X1    9000 non-null float64\n",
      "X2    9000 non-null float64\n",
      "X3    9000 non-null float64\n",
      "X4    9000 non-null object\n",
      "Y     9000 non-null float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 351.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Hyper-parameters\n",
    "\n",
    "- Specify Parameters before running\n",
    "- Value impacts quality and performance of model\n",
    "- Goal is to maximise **performance** and **intelligibility**\n",
    "    - Need a measure for complexity/intelligibility... Depth?\n",
    "- Rule for performance vs complexity\n",
    "    - Maximum depth can increase by 1 for 1% improvement in accuracy\n",
    "- Dividing data into k-folds can be done by sklearn?\n",
    "    - Using 6-folds for 150 per dataset, larger may dilute sets and creat biases.\n",
    "- Mximum depth as a measure of complexity\n",
    "    - Depth of 5? Exponential time complexity?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for Hyper-parameter Tuning goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DT vs Linear Models\n",
    "\n",
    "- Hypothesis which performs well on one class of problems may be bad on another.\n",
    "- Need to **Construct a binary classsification problem**\n",
    "    - Define a function that describes the class lable of a point.\n",
    "    - We know T/F value since we define the problem.\n",
    "    - Generate training and testing data where P and N represent the + and - classes.\n",
    "- Investigate how tree sizes affect performance\n",
    "- Create visualisation of actual and learned class boundaries\n",
    "- Discuss what would happen if the problem was Rd instead of R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "DTree(examples, features) # returns a tree\n",
    "    if all examples are in one class:\n",
    "        return a leaf node with that class label;\n",
    "    elif the set of features is empty:\n",
    "        return a leaf node with the most common class label in examples;\n",
    "    else:\n",
    "        create a new decision (condition) node R;\n",
    "        pick a categorical feature F (or a numeric feature and a threshold);\n",
    "        for each possible outcome v_i of R:\n",
    "            add an out-going edge E_v_i to node R;\n",
    "            let examples_i be the subset of examples that result in outcome v_i;\n",
    "            if examples_i is empty:\n",
    "                attach to E_v_i a leaf node (label) that is \n",
    "                                the most common in examples;\n",
    "            else:\n",
    "                attach to E_v_i the result of DTree(examples_i, features \\ {F});\n",
    "        return the subtree rooted at R.\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for DT goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression on Mixed Data Types\n",
    "\n",
    "- Given data set for a regression problem\n",
    "- Need to train linear regression model\n",
    "- Needs to be linear in weights and features \n",
    "- Has a categorical feature with more than two levels\n",
    "- Use entire dataset for training\n",
    "- Needs to output\n",
    "    - Mean Squared Error\n",
    "    - R^2\n",
    "    - Round coefficients to intigers\n",
    "    - Write a case based definition of the functions identified\n",
    "        - Linear expression of input variables\n",
    "        - One expression per level of variable\n",
    "    - Describe how regression was used\n",
    "    - How a new datapoint can be assigned a predicted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for Regression goes here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
